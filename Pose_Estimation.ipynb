{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtqjqTe-Xgx7"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5_WG-8sXkI9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILqUYFqGXxXI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "from scipy import spatial\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.core.display import ProgressBar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhL3S8Y0XzBJ"
      },
      "outputs": [],
      "source": [
        "# initialize mediapipe requirements\n",
        "mpPose = mp.solutions.pose\n",
        "pose = mpPose.Pose()\n",
        "mpDraw = mp.solutions.drawing_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QESnJ_ItZ27I"
      },
      "outputs": [],
      "source": [
        "# input video path\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/CSE_237D/rock_dataset_0/clip2/climb.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSG0Pn0YnVoE"
      },
      "outputs": [],
      "source": [
        "# global dict to store the coordiantes (required towards MVP)\n",
        "dict_coordinates = {'left_hand': [], 'right_hand': [], 'left_leg': [], 'right_leg': [], 'left_hip': [], 'right_hip': []}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute landmarks for a frame\n",
        "def find_pose(img):\n",
        "  break_signal = False\n",
        "  results = []\n",
        "  try:\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(imgRGB)\n",
        "    print('Landmarks:', results.pose_landmarks)\n",
        "  except:\n",
        "    break_signal = True\n",
        "\n",
        "  return img, results, break_signal\n",
        "  "
      ],
      "metadata": {
        "id": "9pKt-bIyYjsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL5P_5K-nYOK"
      },
      "outputs": [],
      "source": [
        "# retrieve coordinates from lm_list and store the coordinates in the global dict\n",
        "def store_coordinates(lm_list):\n",
        "  global dict_coordinates\n",
        "  dict_coordinates['left_hand'].append((lm_list[38], lm_list[39])) #left_index - x, y \n",
        "  dict_coordinates['right_hand'].append((lm_list[40], lm_list[41])) #right_index - x, y\n",
        "  dict_coordinates['left_hip'].append((lm_list[46], lm_list[47])) #left_hip - x, y\n",
        "  dict_coordinates['right_hip'].append((lm_list[48], lm_list[49])) #right_hip - x, y\n",
        "  dict_coordinates['left_leg'].append((lm_list[62], lm_list[63])) #left_foot - x, y\n",
        "  dict_coordinates['right_leg'].append((lm_list[64], lm_list[65])) #right_foot - x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf8j-SI7nW4u"
      },
      "outputs": [],
      "source": [
        "# compute cosine smilarity between two lm lists \n",
        "def check_similarity(list1, list2):\n",
        "  result = 1 - spatial.distance.cosine(list1, list2)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the image only when the frames are dissimilar\n",
        "def plot_image(img, results, cx, cy, pTime):\n",
        "  mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
        "  cv2.circle(img, (cx, cy), 5, (255,0, 150), cv2.FILLED)\n",
        "  cTime = time.time()\n",
        "  fps = 1 / (cTime - pTime)\n",
        "  pTime = cTime\n",
        "    \n",
        "  cv2.putText(img, str(int(fps)), (50, 50), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 3)\n",
        "  cv2_imshow(img)\n",
        "  cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "UvZveavrx7Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(cap):\n",
        "  prev = []\n",
        "  output_img_list = []\n",
        "  first_frame_flag = True\n",
        "  total_frames_count = 0\n",
        "  stored_frames_count = 0\n",
        "  pTime = 0\n",
        "\n",
        "  while True:\n",
        "    print('----------------------')\n",
        "    print('Processing a new frame')\n",
        "    success, img = cap.read()\n",
        "    img, results, main_break_signal = find_pose(img)\n",
        "    \n",
        "    # the signal means that there are no more input frames in the video, and thus the code must terminate\n",
        "    if (main_break_signal == True):\n",
        "      break\n",
        "    \n",
        "    lm_list = []\n",
        "\n",
        "    if results.pose_landmarks:     \n",
        "      # add all 66 cordinates to lm_list\n",
        "      for id, lm in enumerate(results.pose_landmarks.landmark):  \n",
        "        h, w, c = img.shape\n",
        "        cx, cy = int(lm.x*w), int(lm.y*h)\n",
        "        lm_list.append(cx)\n",
        "        lm_list.append(cy)\n",
        "\n",
        "      # for the first frame, compute and store the coordinates\n",
        "      if(first_frame_flag == True):\n",
        "        store_coordinates(lm_list)\n",
        "        print(\"Similarity found for the first frame and coordinates stored\")\n",
        "        prev = lm_list\n",
        "        first_frame_flag = False\n",
        "        stored_frames_count += 1\n",
        "        output_img_list.append(img)\n",
        "        plot_image(img, results, cx, cy, pTime)\n",
        "\n",
        "\n",
        "      # from next frame onwards, first check similarity and then store the coordinates\n",
        "      else:\n",
        "        result = check_similarity(prev, lm_list) #prev = 66 cordinates, lm_list = 66 cordinates\n",
        "        print('Similarity Value:', result)\n",
        "        if(result < 0.9999):\n",
        "          store_coordinates(lm_list)\n",
        "          print(\"Similarity found and coordinates stored\")\n",
        "          stored_frames_count += 1\n",
        "          output_img_list.append(img)\n",
        "          plot_image(img, results, cx, cy, pTime)\n",
        "        \n",
        "        prev = lm_list\n",
        "          \n",
        "      print('Prev list: ', prev)\n",
        "      print('Length of prev list: ', len(prev))\n",
        "      print('LM list: ', lm_list)\n",
        "      print('Length of lm_list: ', len(lm_list))\n",
        "\n",
        "    total_frames_count += 1\n",
        "\n",
        "  print('---------- Processsing Completed ----------')\n",
        "  print('Total frames processed: ', total_frames_count)\n",
        "  print('Total frames stored: ', stored_frames_count)\n",
        "\n",
        "  # output a video consisting of just the processed frames\n",
        "  width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # float 'width'\n",
        "  height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # float 'height'\n",
        "  img_size = (width, height)\n",
        "  fps = 5\n",
        "  output_video = cv2.VideoWriter('pose_estimation.mp4',cv2.VideoWriter_fourcc(*'mp4v'), fps, img_size)\n",
        " \n",
        "  for i in range(len(output_img_list)):\n",
        "    output_video.write(output_img_list[i])\n",
        "  \n",
        "  output_video.release()\n",
        "  print('Output Video Released: ', fps, 'fps')"
      ],
      "metadata": {
        "id": "VRvP-1ZB9XWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_last_frame_cordinates(cap):\n",
        "  last_frame_cordinates = []\n",
        "\n",
        "  #Run code on input video - cap and store coordinates of all frames in dict_coordinates\n",
        "  main(cap)\n",
        "\n",
        "  #Return last frame coordinates\n",
        "  last_frame_cordinates.append(dict_coordinates['left_hand'][-1])\n",
        "  last_frame_cordinates.append(dict_coordinates['right_hand'][-1])\n",
        "  last_frame_cordinates.append(dict_coordinates['left_hip'][-1])\n",
        "  last_frame_cordinates.append(dict_coordinates['right_hip'][-1])\n",
        "  last_frame_cordinates.append(dict_coordinates['left_leg'][-1])\n",
        "  last_frame_cordinates.append(dict_coordinates['right_leg'][-1])\n",
        "  \n",
        "  return (last_frame_cordinates)"
      ],
      "metadata": {
        "id": "-1PzY08EC3wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UeGf37EaK2g"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main(cap)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Pose_Estimation.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}